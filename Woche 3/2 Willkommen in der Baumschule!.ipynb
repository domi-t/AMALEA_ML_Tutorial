{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Der Befehl \"wget\" ist entweder falsch geschrieben oder\n","konnte nicht gefunden werden.\n","Der Befehl \"wget\" ist entweder falsch geschrieben oder\n","konnte nicht gefunden werden.\n"]}],"source":["# [Nur Colab] Diese Zellen müssen nur auf *Google Colab* ausgeführt werden und installieren Packete und Daten\n","!wget -q https://raw.githubusercontent.com/KI-Campus/AMALEA/master/requirements.txt && pip install --quiet -r requirements.txt\n","!wget --quiet \"https://github.com/KI-Campus/AMALEA/releases/download/data/data.zip\" && unzip -q data.zip"]},{"cell_type":"markdown","metadata":{},"source":["# Willkommen in der Baumschule!   "]},{"cell_type":"markdown","metadata":{},"source":["## Einführung\n","\n","Entscheidungsbäume sind die Bausteine einer der leistungsstärksten Methoden des **überwachten Lernens** (z. B. mit einer vordefinierten Zielvariablen), die heute verwendet werden. Falls Sie bereits eine Fehlerdiagnose bei einem Gerät, einem Auto oder einem Computer durchführen mussten, ist es gut möglich, dass Sie schon einmal einem Flussdiagramm zur Fehlerbehebung begegnet sind. Flussdiagramme sind visuelle Darstellungen von Entscheidungsbäumen. Zum Beispiel veröffentlicht die Higher School of Economics Informationsdiagramme, um das Leben ihrer MitarbeiterInnen zu erleichtern. Hier ist ein Ausschnitt aus der Anleitung für die Veröffentlichung eines Papers im Portal der Hochschule. \n","<img src=\"images/snipped_GER.png\">"]},{"cell_type":"markdown","metadata":{},"source":["## Klassifizierungs- und Regressionsbäume (CART)\n","\n","Classification and Regression Trees (Klassifizierungs- und Regressionsbäume) ist ein Akronym, das 1984 von Leo Breiman eingeführt wurde. Es bezeichnet Entscheidungsbaum-Algorithmen, die für prädiktive Modellierungsprobleme verwendet werden können. Wir werden uns in dieser Übung auf den CART-Algorithmus konzentrieren."]},{"cell_type":"markdown","metadata":{},"source":["### CART\n","\n","Das CART-Modell wird in Form eines binäreren Entscheidungsbaums dargestellt. Dabei handelt es sich um den gleichen binären Baum, den Sie vielleicht von Algorithmen und Datenstrukturen kennen. Jeder Knoten des Binärbaums kann null, einen oder zwei Kindknoten haben.\n","\n","Ein Knoten repräsentiert eine einzelne Eingabevariable (X) und einen Aufteilungspunkt (engl. split point) auf dieser Variable (vorausgesetzt, die Variable ist numerisch). Die Blatt- oder Endknoten des Baums enthalten eine Ausgangsvariable (Y), die für eine Vorhersage verwendet wird. \n","\n","Beim Erstellen eines binären Entscheidungsbaums wird der Eingaberaum aufgeteilt. Dazu wird das sogenannte rekursive binäre Splitting verwendet (greedy Ansatz). Hierbei handelt es sich um ein numerisches Verfahren, bei dem alle Werte aneinandergereiht werden und verschiedene Aufteilungspunkte mit Hilfe einer Kostenfunktion ausprobiert und bewertet werden.\n","\n","Der Split mit den besten Kosten (niedrigste Kosten, da wir die Kosten minimieren) wird ausgewählt. Alle Eingangsvariablen und alle möglichen Aufteilungspunkte werden ausgewertet und auf Grundlage der Kostenfunktion (greedy) ausgewählt.\n","\n","- **Regression:** Die Kostenfunktion, die zum Finden der Splitpunkte minimiert wird, ist die **Summe des quadrierten Fehlers** über alle Trainingsstichproben, die in das Rechteck fallen.\n","\n","- **Klassifizierung:** Es wird die *Gini*-Kostenfunktion verwendet, die einen Hinweis darauf liefert, wie rein die Knoten sind. Die Knotenreinheit bezieht sich dabei darauf, wie gemischt die jedem Knoten zugewiesenen Trainingsdaten sind.\n","\n","Die Aufteilung wird fortgesetzt, bis die Knoten eine Mindestanzahl von Trainingsbeispielen enthalten oder eine maximale Baumtiefe erreicht ist.\n","\n","In dieser Aufgabe konzentrieren wir uns nur auf die Klassifizierungseigenschaft des Algorithmus."]},{"cell_type":"markdown","metadata":{},"source":["### Metriken\n","\n","#### Gini-Index\n","\n","Der Gini-Index ist die Kostenfunktion, die zum Bewerten der Aufteilungen des Datensatzes verwendet wird. Eine Aufteilung umfasst ein Eingabeattribut und einen Wert für dieses Attribut. Der Gini-Score gibt eine Vorstellung davon, wie gut eine Aufteilung ist, da er angibt, wie gemischt die Klassen in den beiden Gruppen sind, die durch die Aufteilung entstanden sind. Eine perfekte Aufteilung ergibt einen Gini-Score von 0, während die schlechteste Aufteilung, z. B. eine 50/50-Aufteilung, für ein Zwei-Klassen-Problem einen Gini-Score von 0,5 ergibt.\n","\n","Die Berechnung des Gini-Scores lässt sich am besten anhand eines Beispiels demonstrieren:\n","\n","<img src=\"images/iris_tree.png\">\n","\n","Angenommen, Sie finden eine Irisblüte und wollen sie klassifizieren. In der obigen Abbildung beginnen wir im *Wurzelknoten*: Dieser Knoten überprüft, ob die Länge des Blütenblatts kleiner als 2,45 cm ist. Wenn das der Fall ist, gehen wir zum linken Kindknoten der Wurzel hinunter. Dieser Knoten ist ein *Blattknoten*, da er keine Kinder besitzt. \n","\n","Nehmen wir nun an, wir finden eine weitere Blume. Diese besitzt eine Blütenblattlänge, die größer als 2,45 cm ist. Angefangen bei der Wurzel kommen wir so zum rechten Kindknoten, der kein Blattknoten ist. Dieser Knoten möchte wissen, ob die Breite des Blütenblatts kleiner als 1,75 cm ist. Wenn das der Fall ist, dann ist unsere Blume höchstwahrscheinlich eine Iris-Versicolor. Andernfalls handelt es sich wahrscheinlich um eine Iris-Virginica.\n","\n","Angenommen, wir haben 100 Trainingsinstanzen mit einer Blütenblattlänge größer als 2,45 cm, darunter 54 mit einer Blütenblattbreite kleiner als 1,75 cm. Das Wertattribut eines Knotens gibt an, auf wie viele Trainingsinstanzen jeder Klasse dieser Knoten zutrifft: Der Knoten unten rechts trifft auf 0 Iris-Setosa, 1 Iris-Versicolor und 45 Iris-Virginica zu. Gemäß Gleichung (\\ref{eq1}) setzt sich der Gini-Score wie folgt zusammen: $1-(0/54)^2-(49/54)^2-(5/54)^2 = 0.168$.\n","\n","\\begin{equation*}\n","G_i = 1 - \\sum_{k=0}^{n-1} p_{i,k}^2\n","\\label{eq1}\\tag{1}\n","\\end{equation*}\n","wobei $p_{i,k}$ das Verhältnis der Instanzen der Klasse k unter den Trainingsinstanzen im $i^{th}$-Knoten beschreibt."]},{"cell_type":"markdown","metadata":{},"source":["## Importe"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","%matplotlib inline\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["## Entscheidungsbäume mit scikit-learn\n","\n","Nun haben wir unseren Datensatz für die Algorithmen des maschinellen Lernens vorbereitet. Zu Beginn haben wir die Idee der Klassifizierung und Regression mit Entscheidungsbäumen beschrieben. Im Folgenden werden wir die Implementierung von Entscheidungsbäumen mittels scikit-learn verwenden, um die binäre Klassifizierung des Titanic Datensatzes durchzuführen.\n","\n","\n","## Entscheidungsbäume ohne Parameteroptimierung (engl. parameter tuning)\n","\n","#### Importieren der Bibliotheken\n","Der erste Schritt besteht darin, den Algorithmus \"wie er ist\" zu verwenden, ohne irgendwelche Parameter anzupassen. Importieren Sie daher die notwendige Bibliothek/Funktion von scikit-learn, die den DecisionTreeClassifier enthält. Außerdem muss die Funktion export_graphviz importiert werden, die für die Darstellung der Ergebnisse der Entscheidungsbäume benötigt wird. Um das Modell zu evaluieren, müssen wir ein Train- und ein Validation-Set erzeugen, indem wir den train-test split von scikit-learn verwenden. Importieren Sie daher die notwendigen Funktionen. Um die Performance der trainierten Entscheidungsbäume zu vergleichen, müssen wir zunächst den DummyClassifier importieren. Der DummyClassifer https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html ist in der Lage, Datenpunkte gleichmäßig zufällig zu klassifizieren oder immer das häufigste Label im Trainingssatz vorherzusagen. Importieren Sie den accuracy score des Pakets 'metrics' für die Evaluierung der Klassifizierungsergebnisse."]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.1:</b> Importieren Sie die im Text oben genannten Funktionen.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","<b>Hinweis:</b> Falls graphviz nicht installiert ist, versuchen Sie folgende Schritte.  \n","<ul>\n","<li> 1. Ansatz: Öffnen Sie anaconda, anschließend gehen Sie zu den Umgebungen (engl. environments) und wählen Sie diejenige aus, an der Sie gerade arbeiten. Suchen Sie dann nach graphviz und installieren Sie es.\n","<li> 2. Ansatz: Öffnen Sie ein Terminal innerhalb Ihrer Umgebung, indem Sie auf den grünen Pfeil Ihrer Umgebung klicken. Anschließend:\n","<ul>\n","<li> Aktivieren Sie Ihre Umgebung: conda activate environment_name\n","    <li> Installieren Sie pip: conda install pip (gegebenfalls bereits installiert)\n","    <li> installieren Sie graphviz: conda install python-graphviz\n","    </ul>\n","</li>\n","\n","</ul>\n","<br>\n","\n","</div>"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["# STUDENT CODE HERE\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.dummy import DummyClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# STUDENT CODE until HERE\n","\n","from graphviz import Source"]},{"cell_type":"markdown","metadata":{},"source":["#### Generieren von Training-, Validierung- und Test-Datensatz\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.2:</b> \n","<ul>\n","<li>Laden Sie die Datensätze aus der Lösung der Vorbereitungsdatei (train_prepared.csv,...).\n","<li>Nehmen Sie die Spalte mit den Labeldaten sowohl im Trainingsatz als auch im Testsatz und entfernen diese vom Datensatz. \n","<li>Teilen Sie den \"train\"-Teil des Datensatzes in 80 % Trainingsdaten und 20 % Validierungsdaten auf. Verwenden Sie den Parameter random_state = 17 für die Reproduzierbarkeit der Ergebnisse.\n","<li> Hinweis: Sie könnten den originalen Trainigsatz für das Kreuzvalidierungsverfahren (engl. Cross Validation) später benötigen. \n","</ul>\n","    \n","<b>Wichtige Information:</b> Beim überwachten Lernen bestehen die Datensätze immer aus Labels und Features. Nachdem Sie Ihr Modell trainiert haben, geben Sie ihm neue Input Datensätze, die Features (Alter, Geschlecht usw.) enthalten; es gibt das vorhergesagte Label ('Survived') für diese Person zurück.<br>\n","</div>"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Name_length</th>\n","      <th>Fare_log</th>\n","      <th>Fare_bin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>873</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>9.0000</td>\n","      <td>1</td>\n","      <td>2.197225</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>828</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>7.7500</td>\n","      <td>1</td>\n","      <td>2.047693</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>26.0000</td>\n","      <td>0</td>\n","      <td>3.258097</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>523</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>44</td>\n","      <td>1</td>\n","      <td>57.9792</td>\n","      <td>3</td>\n","      <td>4.060084</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>47</td>\n","      <td>0</td>\n","      <td>14.5000</td>\n","      <td>3</td>\n","      <td>2.674149</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>51</td>\n","      <td>0</td>\n","      <td>7.7500</td>\n","      <td>2</td>\n","      <td>2.047693</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>36</td>\n","      <td>2</td>\n","      <td>120.0000</td>\n","      <td>1</td>\n","      <td>4.787492</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>6.7500</td>\n","      <td>0</td>\n","      <td>1.909543</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>241</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>38</td>\n","      <td>0</td>\n","      <td>15.5000</td>\n","      <td>2</td>\n","      <td>2.740840</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>623</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>7.8542</td>\n","      <td>1</td>\n","      <td>2.061048</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>712 rows × 8 columns</p>\n","</div>"],"text/plain":["     Pclass  Sex  Age  Parch      Fare  Name_length  Fare_log  Fare_bin\n","873       3    0   47      0    9.0000            1  2.197225         0\n","828       3    0   25      0    7.7500            1  2.047693         0\n","99        2    0   34      0   26.0000            0  3.258097         1\n","523       1    1   44      1   57.9792            3  4.060084         1\n","132       3    1   47      0   14.5000            3  2.674149         0\n","..      ...  ...  ...    ...       ...          ...       ...       ...\n","406       3    0   51      0    7.7500            2  2.047693         0\n","390       1    0   36      2  120.0000            1  4.787492         1\n","143       3    0   19      0    6.7500            0  1.909543         0\n","241       3    1   38      0   15.5000            2  2.740840         1\n","623       3    0   21      0    7.8542            1  2.061048         0\n","\n","[712 rows x 8 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# STUDENT CODE HERE\n","data_original = pd.read_csv('data/train_prepared.csv')\n","X = data_original.drop(columns=[\"Survived\"])\n","Y = data_original['Survived']\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=17)\n","X_train\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["#### Validierung des Dummy Klassifikators\n","\n","Um einen Eindruck zu bekommen, ob die Klassifizierung mit dem Modell sinnvoll ist, verwenden wir den DummyClassifier, der zufällig entscheidet.  \n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.3:</b> \n","<ul>\n","<li> Trainieren Sie den Klassifikator mit dem entsprechenden Parameterwert 'most_frequent' für die Strategie\n","<li> Benutzen Sie den Parameter random_state = 17 (für die Reproduzierbarkeit der Ergebnisse)\n","<li> Berechnen Sie die Korrektklassifikationsrate (engl. accuracy), um die Klassifizierungsgenauigkeit für die Validierungsdaten zu erhalten\n","<li> Hinweis: Besuchen Sie die Website von scikit-learn, um den Klassifikator zu importieren, ihn zu trainieren, mit ihm Vorhersagen zu treffen und die Korrektklassifikationsrate zu berechnen\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["0.5921787709497207"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# STUDENT CODE HERE\n","dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=17)\n","dummy_clf.fit(X_train, y_train)\n","y_pred = dummy_clf.predict(X_test)\n","score = accuracy_score(y_test, y_pred)\n","score\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 3.2.4:</b> Wie interpretieren Sie dieses Ergebnis? \n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div> nur 59% richtige Erkennungsquote\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Validierung des Entscheidungsbaums\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.5:</b> \n","<ul>\n","<li> Trainieren Sie einen Entscheidungsbaum (mit DecisionTreeClassifier) mit einer maximalen Tiefe von 2\n","<li> Evaluieren Sie die Korrektklassifikationsrate Metrik (engl. accuracy metric) anhand der Validierungsdaten. \n","<li> Benutzen Sie den Parameter random_state = 17 für die Reproduzierbarkeit der Ergebnisse.\n","<li> Hinweis: Syntax oder Funktionen mit diesem Klassifikator sind für Training etc. gleich.\n","    </li>\n","    \n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["0.7821229050279329"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# STUDENT CODE HERE\n","dtc = DecisionTreeClassifier(random_state=17, max_depth=2)\n","dtc.fit(X_train, y_train)\n","y_pred = dtc.predict(X_test)\n","score = accuracy_score(y_test, y_pred)\n","score\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 3.2.6:</b>  Was können Sie beobachten, wenn wir die Korrektklassifikationsrate mit der des DummyClassifiers vergleichen?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div> Deutlich besser\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Das trainierte Modell verstehen\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.7:</b> \n","<ul>\n","<li> Plotten Sie den Baum mit sklearn.tree.export_graphviz und graphviz\n","<li> Geben Sie die Namen der Features sowie die Klassennamen entsprechend dem Datensatz aus.\n","<li> Hinweis: Benutzen Sie dataframe.columns.values und Source(export_graphviz)\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/plain":["'Source.gv.pdf'"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["# STUDENT CODE HERE\n","from sklearn import tree\n","\n","import os\n","os.environ[\"PATH\"] += os.pathsep + 'D:/Tools/Graphviz/bin'\n","\n","tree_plot = tree.export_graphviz(dtc, feature_names=X_train.columns)\n","s = Source(tree_plot)\n","s.view()\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 3.2.8:</b>  Welche Features werden für Vorhersagen im erstellten Entscheidungsbaum verwendet? Welche der verbleibenden Splits (in der letzten Zeile des Baums) ist derzeit die Präziseste?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div> GEschlecht, Alter und Buchungsklasse\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Testen der Generalisierung\n","\n","In den vorherigen Aufgaben haben wir die Performance unseres Algorithmus an einem einzelnen Train-Test-Split unseres Training-Datensatzes evaluiert. Lassen Sie uns nun die Kreuzvalidierung (engl. cross validation) verwenden, um eine bessere Schätzung des Generalisierungsfehlers zu erhalten.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.9:</b> Importieren Sie die notwendige Bibliothek für die Kreuzvalidierung (engl. cross validation) mit StratifiedKFold.\n","</div>"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# STUDENT CODE HERE\n","from sklearn.model_selection import StratifiedKFold\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.10:</b> \n","<ul>\n","<li> Führen Sie eine 5-fache geschichtete Kreuzvalidierung (engl. 5-fold stratified cross validation) durch\n","<li> Berechnen Sie die mittlere Korrektklassifikationsrate (engl. mean accuracy) und die Standardabweichung der Korrektklassifikationsrate (engl. accuracy)\n","<li> Verwenden Sie eine maximale Tiefe von 2 und random_state = 17 für den Baum und die Folds\n","<li> Vergessen Sie nicht, den gesamten Trainingssatz zu verwenden (bevor Sie ihn in train,val aufteilen)\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy per fold:  [0.770949720670391, 0.7640449438202247, 0.7191011235955056, 0.8146067415730337, 0.7696629213483146] \n","\n","Average accuracy:  0.7676730902014939\n"]}],"source":["# STUDENT CODE HERE\n","kf = StratifiedKFold(n_splits=5, random_state=17, shuffle=True)\n","\n","model = DecisionTreeClassifier(max_depth=2, random_state=17)\n","fold_accuracy = []\n","\n","for train_index, valid_index in kf.split(X, Y):\n","    train_x, test_x = X.iloc[train_index], X.iloc[valid_index]\n","    train_y, test_y = Y.iloc[train_index], Y.iloc[valid_index]\n","\n","    model_run = model.fit(train_x, train_y)\n","    valid_acc = model_run.score(test_x, test_y)\n","    fold_accuracy.append(valid_acc)\n","\n","print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n","print(\"Average accuracy: \", sum(fold_accuracy)/len(fold_accuracy))\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["### Parameteroptimierung für Entscheidungsbäume\n","\n","Der wichtigste Parameter eines Entscheidungsbaums ist die Tiefe des Baums. Daher ist es notwendig, verschiedene Tiefen des Baums zu evaluieren, um die optimale Leistung hinsichtlich der Korrektklassifikationsrate (engl. classification accuracy) zu erreichen. Zu diesem Zweck verwenden wir die Gittersuche (engl. grid search) in Kombination mit dem Kreuzvalidierungsverfahren (engl. cross validation), das wir zuvor verwendet haben. Glücklicherweise hat scikit-learn bereits eine schöne und einfach zu bedienende Schnittstelle für dieses Problem implementiert. Die Funktion heißt `GridSearchCV` und ist in der Bibliothek sklearn.model_selection zu finden. \n","\n","\n","#### Verwendung von Grid Search Cross-Validation zur Optimierung der Baumtiefe\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.11:</b> \n","<ul>\n","<li> Laden Sie die Bibliothek GridSearchCV und trainieren Sie einen Entscheidungsbaum (DecisionTreeClassifier, random_state = 17)\n","<li> Ermitteln Sie die optimale maximale Tiefe mit 5-facher geschichteter Kreuzvalidierung (engl. 5-fold stratified cross-validation) und gleichem RandomState \n","<li> Variieren Sie die Tiefe des Baums zwischen 1 und 13.\n","<li> Vergessen Sie nicht, den gesamten Trainingssatz zu verwenden (bevor Sie ihn in train,val aufteilen)\n","<li> Hinweis: Verwenden Sie die scikit-learn-Website für weitere Informationen zu den Funktionen\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'max_depth': 1, 'random_state': 17}, 0.786761659657272\n","{'max_depth': 2, 'random_state': 17}, 0.7676730902014939\n","{'max_depth': 3, 'random_state': 17}, 0.8136840123030569\n","{'max_depth': 4, 'random_state': 17}, 0.8159312033142928\n","{'max_depth': 5, 'random_state': 17}, 0.818172117255665\n","{'max_depth': 6, 'random_state': 17}, 0.7968551879982424\n","{'max_depth': 7, 'random_state': 17}, 0.7990961019396146\n","{'max_depth': 8, 'random_state': 17}, 0.792348251836043\n","{'max_depth': 9, 'random_state': 17}, 0.7934655702717972\n","{'max_depth': 10, 'random_state': 17}, 0.7755068733915009\n","{'max_depth': 11, 'random_state': 17}, 0.7665306634862846\n","{'max_depth': 12, 'random_state': 17}, 0.7755131504613646\n","{'max_depth': 13, 'random_state': 17}, 0.7530475174188689\n"]}],"source":["# STUDENT CODE HERE\n","from sklearn.model_selection import GridSearchCV\n","\n","model = DecisionTreeClassifier()\n","tree_param = {'random_state': [17], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]}\n","strat_5fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n","\n","estimator = GridSearchCV(DecisionTreeClassifier(), tree_param, cv=strat_5fold)\n","estimator.fit(X, Y)\n","\n","results = estimator.cv_results_\n","for i in range(len(results['params'])):\n","    print(\"{}, {}\".format(results['params'][i], results['mean_test_score'][i]))\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.12:</b> \n","<ul>\n","<li> Zeichnen Sie ein Diagramm zur Darstellung der durchschnittlichen Korrektklassifikationsrate über die Tiefe \n","<li> Benutzen Sie das Attribut <code>.cv_results</code>, um die durchschnittliche Korrektklassifikationsrate mit Hilfe von 'mean_test_score' zu erhalten.\n","</ul>\n","</div>"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x2689caf78c8>]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# STUDENT CODE HERE\n","results['params']\n","x_plot = np.linspace(1, 13,13)\n","plt.plot(x_plot, results['mean_test_score']) \n","\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 3.2.13:</b>  Was sind die besten Parameterwerte? Wie hoch ist die Korrektklassifikationsrate (Kreuzvaliderungsverfahren) des Modells mit dieser Baumtiefe?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# STUDENT CODE HERE\n","# 4+5 ist die optimale Tiefe, ~82%\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["Für unsere Trainingsdaten haben wir den optimalen Parameter gefunden. Schließlich können wir die Perfomance bewerten, indem wir unsere Trainingsdaten zum Trainieren und unseren Testdatensatz zum Testen verwenden. Verwenden Sie im Folgenden immer eine Baumtiefe von 3. \n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.14:</b> \n","<ul>\n","<li> Trainieren Sie einen Entscheidungsbaum bei einer Baumtiefe von drei, unter Verwendung aller Trainingsdaten (keine Kreuzvalidierung)\n","<li> Berechnen Sie die Korrektklassifikationsrate (engl. accuracy) für den Testdatensatz. Verwenden Sie den Parameter random_state = 17 für die Reproduzierbarkeit.\n","</ul>\n","</div>\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["0.7932960893854749"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# STUDENT CODE HERE\n","model = DecisionTreeClassifier(random_state=17, max_depth=3)\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=17)\n","\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","acc2 = accuracy_score(y_test, y_pred)\n","acc2\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1039pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 1038.50 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-429 1034.5,-429 1034.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f5ceb1\" stroke=\"black\" d=\"M564,-425C564,-425 458,-425 458,-425 452,-425 446,-419 446,-413 446,-413 446,-354 446,-354 446,-348 452,-342 458,-342 458,-342 564,-342 564,-342 570,-342 576,-348 576,-354 576,-354 576,-413 576,-413 576,-419 570,-425 564,-425\"/>\n<text text-anchor=\"start\" x=\"480.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"477.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.47</text>\n<text text-anchor=\"start\" x=\"463.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 712</text>\n<text text-anchor=\"start\" x=\"454\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [443, 269]</text>\n<text text-anchor=\"start\" x=\"469\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Dead</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#eb9d65\" stroke=\"black\" d=\"M434,-306C434,-306 336,-306 336,-306 330,-306 324,-300 324,-294 324,-294 324,-235 324,-235 324,-229 330,-223 336,-223 336,-223 434,-223 434,-223 440,-223 446,-229 446,-235 446,-235 446,-294 446,-294 446,-300 440,-306 434,-306\"/>\n<text text-anchor=\"start\" x=\"354\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 6.5</text>\n<text text-anchor=\"start\" x=\"347.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.299</text>\n<text text-anchor=\"start\" x=\"337.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 465</text>\n<text text-anchor=\"start\" x=\"332\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [380, 85]</text>\n<text text-anchor=\"start\" x=\"343\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Dead</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M467.28,-341.91C457.22,-332.56 446.43,-322.54 436.08,-312.93\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"438.35,-310.26 428.64,-306.02 433.58,-315.39 438.35,-310.26\"/>\n<text text-anchor=\"middle\" x=\"429.56\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#7dbfee\" stroke=\"black\" d=\"M694,-306C694,-306 596,-306 596,-306 590,-306 584,-300 584,-294 584,-294 584,-235 584,-235 584,-229 590,-223 596,-223 596,-223 694,-223 694,-223 700,-223 706,-229 706,-235 706,-235 706,-294 706,-294 706,-300 700,-306 694,-306\"/>\n<text text-anchor=\"start\" x=\"605.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"611.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.38</text>\n<text text-anchor=\"start\" x=\"597.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 247</text>\n<text text-anchor=\"start\" x=\"592\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [63, 184]</text>\n<text text-anchor=\"start\" x=\"593\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Survived</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M557.49,-341.91C568.3,-332.47 579.9,-322.34 591,-312.65\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"593.36,-315.23 598.59,-306.02 588.76,-309.96 593.36,-315.23\"/>\n<text text-anchor=\"middle\" x=\"596.9\" y=\"-327.26\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#acd6f4\" stroke=\"black\" d=\"M238,-187C238,-187 142,-187 142,-187 136,-187 130,-181 130,-175 130,-175 130,-116 130,-116 130,-110 136,-104 142,-104 142,-104 238,-104 238,-104 244,-104 250,-110 250,-116 250,-116 250,-175 250,-175 250,-181 244,-187 238,-187\"/>\n<text text-anchor=\"start\" x=\"150.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"152.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.465</text>\n<text text-anchor=\"start\" x=\"146.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"145.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 12]</text>\n<text text-anchor=\"start\" x=\"138\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Survived</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M323.84,-226.8C303.22,-214.43 280.08,-200.55 258.91,-187.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"260.65,-184.81 250.28,-182.67 257.05,-190.81 260.65,-184.81\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#ea9a60\" stroke=\"black\" d=\"M434,-187C434,-187 336,-187 336,-187 330,-187 324,-181 324,-175 324,-175 324,-116 324,-116 324,-110 330,-104 336,-104 336,-104 434,-104 434,-104 440,-104 446,-110 446,-116 446,-116 446,-175 446,-175 446,-181 440,-187 434,-187\"/>\n<text text-anchor=\"start\" x=\"345.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"347.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.274</text>\n<text text-anchor=\"start\" x=\"337.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 446</text>\n<text text-anchor=\"start\" x=\"332\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [373, 73]</text>\n<text text-anchor=\"start\" x=\"343\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Dead</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M385,-222.91C385,-214.65 385,-205.86 385,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"388.5,-197.02 385,-187.02 381.5,-197.02 388.5,-197.02\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M108,-68C108,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 108,0 108,0 114,0 120,-6 120,-12 120,-12 120,-56 120,-56 120,-62 114,-68 108,-68\"/>\n<text text-anchor=\"start\" x=\"31\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"20.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"19.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Survived</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M141.59,-103.73C130.44,-94.33 118.59,-84.35 107.47,-74.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.44,-72.06 99.53,-68.3 104.93,-77.42 109.44,-72.06\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#f4c9aa\" stroke=\"black\" d=\"M229.5,-68C229.5,-68 150.5,-68 150.5,-68 144.5,-68 138.5,-62 138.5,-56 138.5,-56 138.5,-12 138.5,-12 138.5,-6 144.5,0 150.5,0 150.5,0 229.5,0 229.5,0 235.5,0 241.5,-6 241.5,-12 241.5,-12 241.5,-56 241.5,-56 241.5,-62 235.5,-68 229.5,-68\"/>\n<text text-anchor=\"start\" x=\"152.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.463</text>\n<text text-anchor=\"start\" x=\"146.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"149.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 4]</text>\n<text text-anchor=\"start\" x=\"148\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Dead</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M190,-103.73C190,-95.52 190,-86.86 190,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"193.5,-78.3 190,-68.3 186.5,-78.3 193.5,-78.3\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#f3c4a2\" stroke=\"black\" d=\"M360.5,-68C360.5,-68 271.5,-68 271.5,-68 265.5,-68 259.5,-62 259.5,-56 259.5,-56 259.5,-12 259.5,-12 259.5,-6 265.5,0 271.5,0 271.5,0 360.5,0 360.5,0 366.5,0 372.5,-6 372.5,-12 372.5,-12 372.5,-56 372.5,-56 372.5,-62 366.5,-68 360.5,-68\"/>\n<text text-anchor=\"start\" x=\"278.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.453</text>\n<text text-anchor=\"start\" x=\"272.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 95</text>\n<text text-anchor=\"start\" x=\"267.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [62, 33]</text>\n<text text-anchor=\"start\" x=\"274\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Dead</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M359.31,-103.73C353.79,-94.97 347.95,-85.7 342.41,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"345.28,-74.89 336.98,-68.3 339.35,-78.63 345.28,-74.89\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#e89152\" stroke=\"black\" d=\"M501,-68C501,-68 403,-68 403,-68 397,-68 391,-62 391,-56 391,-56 391,-12 391,-12 391,-6 397,0 403,0 403,0 501,0 501,0 507,0 513,-6 513,-12 513,-12 513,-56 513,-56 513,-62 507,-68 501,-68\"/>\n<text text-anchor=\"start\" x=\"414.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.202</text>\n<text text-anchor=\"start\" x=\"404.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 351</text>\n<text text-anchor=\"start\" x=\"399\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [311, 40]</text>\n<text text-anchor=\"start\" x=\"410\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Dead</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M409.95,-103.73C415.31,-94.97 420.98,-85.7 426.36,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"429.39,-78.66 431.62,-68.3 423.42,-75 429.39,-78.66\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#43a2e6\" stroke=\"black\" d=\"M693,-187C693,-187 597,-187 597,-187 591,-187 585,-181 585,-175 585,-175 585,-116 585,-116 585,-110 591,-104 597,-104 597,-104 693,-104 693,-104 699,-104 705,-110 705,-116 705,-116 705,-175 705,-175 705,-181 699,-187 693,-187\"/>\n<text text-anchor=\"start\" x=\"614\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"607.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.087</text>\n<text text-anchor=\"start\" x=\"597.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 131</text>\n<text text-anchor=\"start\" x=\"596.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 125]</text>\n<text text-anchor=\"start\" x=\"593\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Survived</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M645,-222.91C645,-214.65 645,-205.86 645,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"648.5,-197.02 645,-187.02 641.5,-197.02 648.5,-197.02\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#f8fcfe\" stroke=\"black\" d=\"M895,-187C895,-187 799,-187 799,-187 793,-187 787,-181 787,-175 787,-175 787,-116 787,-116 787,-110 793,-104 799,-104 799,-104 895,-104 895,-104 901,-104 907,-110 907,-116 907,-116 907,-175 907,-175 907,-181 901,-187 895,-187\"/>\n<text text-anchor=\"start\" x=\"806\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 23.35</text>\n<text text-anchor=\"start\" x=\"818\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"799.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 116</text>\n<text text-anchor=\"start\" x=\"798.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [57, 59]</text>\n<text text-anchor=\"start\" x=\"795\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Survived</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M706.15,-228.08C728.81,-214.96 754.64,-199.99 777.95,-186.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"779.85,-189.44 786.75,-181.4 776.34,-183.38 779.85,-189.44\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M619,-68C619,-68 543,-68 543,-68 537,-68 531,-62 531,-56 531,-56 531,-12 531,-12 531,-6 537,0 543,0 543,0 619,0 619,0 625,0 631,-6 631,-12 631,-12 631,-56 631,-56 631,-62 625,-68 619,-68\"/>\n<text text-anchor=\"start\" x=\"552\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"541.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"540.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n<text text-anchor=\"start\" x=\"539\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Dead</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M621.17,-103.73C616.1,-95.06 610.75,-85.9 605.65,-77.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"608.53,-75.17 600.46,-68.3 602.49,-78.7 608.53,-75.17\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#41a1e6\" stroke=\"black\" d=\"M757,-68C757,-68 661,-68 661,-68 655,-68 649,-62 649,-56 649,-56 649,-12 649,-12 649,-6 655,0 661,0 661,0 757,0 757,0 763,0 769,-6 769,-12 769,-12 769,-56 769,-56 769,-62 763,-68 757,-68\"/>\n<text text-anchor=\"start\" x=\"671.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.075</text>\n<text text-anchor=\"start\" x=\"661.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 129</text>\n<text text-anchor=\"start\" x=\"660.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 124]</text>\n<text text-anchor=\"start\" x=\"657\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Survived</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M668.83,-103.73C673.9,-95.06 679.25,-85.9 684.35,-77.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"687.51,-78.7 689.54,-68.3 681.47,-75.17 687.51,-78.7\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#baddf6\" stroke=\"black\" d=\"M895,-68C895,-68 799,-68 799,-68 793,-68 787,-62 787,-56 787,-56 787,-12 787,-12 787,-6 793,0 799,0 799,0 895,0 895,0 901,0 907,-6 907,-12 907,-12 907,-56 907,-56 907,-62 901,-68 895,-68\"/>\n<text text-anchor=\"start\" x=\"809.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.477</text>\n<text text-anchor=\"start\" x=\"803.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 94</text>\n<text text-anchor=\"start\" x=\"798.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [37, 57]</text>\n<text text-anchor=\"start\" x=\"795\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Survived</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M847,-103.73C847,-95.52 847,-86.86 847,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"850.5,-78.3 847,-68.3 843.5,-78.3 850.5,-78.3\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#e88e4d\" stroke=\"black\" d=\"M1018.5,-68C1018.5,-68 937.5,-68 937.5,-68 931.5,-68 925.5,-62 925.5,-56 925.5,-56 925.5,-12 925.5,-12 925.5,-6 931.5,0 937.5,0 937.5,0 1018.5,0 1018.5,0 1024.5,0 1030.5,-6 1030.5,-12 1030.5,-12 1030.5,-56 1030.5,-56 1030.5,-62 1024.5,-68 1018.5,-68\"/>\n<text text-anchor=\"start\" x=\"940.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.165</text>\n<text text-anchor=\"start\" x=\"934.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"933.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [20, 2]</text>\n<text text-anchor=\"start\" x=\"936\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Dead</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M895.78,-103.73C907.13,-94.24 919.19,-84.16 930.49,-74.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"932.73,-77.4 938.16,-68.3 928.24,-72.03 932.73,-77.4\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.sources.Source at 0x2689cbe1848>"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["dot_data = tree.export_graphviz(\n","    model, out_file=None, feature_names=X_train.columns.values, class_names=['Dead','Survived'],  filled=True,\n","    rounded=True, special_characters=True\n",")  \n","graph = Source(dot_data)\n","graph "]},{"cell_type":"markdown","metadata":{},"source":["#### Vergleich von Ergebnissen mit der nicht optimierten Version\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.15:</b> Bestimmen Sie die Wirkung von GridSearchCV\n","<ul>\n","<li> Benutzen Sie folgenden Ausdruck: (acc2 - acc1) / acc1 * 100%\n","<li> acc1 und acc2 sind die Korrektklassifikationsrate (engl. accuracies) der Kreuzvalidierung vor und nach der Optimierung von max_depth mit GridSearchCV \n","<li> Hinweis: acc1 wurde bereits vor der Optimierung verwendet, berechnen Sie daher acc2 zum Vergleich\n","<li> Geben Sie die Verbesserung (berechnet durch den Ausdruck) und die mittlere Korrektklassifikationsrate (engl. accuracy) des optimierten dec_tree aus. Verwenden Sie eine Baumtiefe von 3 und einen random_state = 17 für die Reproduzierbarkeit. \n","</ul>\n","</div>\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["0.014285714285714414"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# STUDENT CODE HERE\n","(acc2 - score) / score * 100\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 3.2.16:</b> Was sind die Vorteile des \"grid search\" - Verfahrens?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Einfluss der Skalierung\n","\n","Als letzten Schritt wollen wir den Einfluss unterschiedlicher Skalierungen auf unsere Trainingsdaten auswerten.\n","\n","##### Skalieren der Datensätze mit Standard Scaler und MinMaxScaler\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.17:</b> \n","\n","Laden Sie die in sklearn.preprocessing enthaltenen Funktionen für den StandardScaler und den MinMaxScaler.\n","\n","</div>"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# STUDENT CODE HERE\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.18:</b> Bereiten Sie zwei verschiedene Datensätze vor, einen skaliert mit StandardScaler und den anderen mit MinMaxScaler.\n","<ul>\n","<li> Erstellen Sie die entsprechenden Skalierer und verwenden Sie die Methode <code>.fit_transform()</code> unter Verwendung des gesamten Trainingsdatensatzes\n","<li> Transformieren Sie dann den Testdatensatz mit den angepassten Skalern mithilfe der Funktion transform\n","    \n","</ul>\n","</div>\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Name_length</th>\n","      <th>Fare_log</th>\n","      <th>Fare_bin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.2750</td>\n","      <td>0.000000</td>\n","      <td>0.014151</td>\n","      <td>0.000000</td>\n","      <td>0.317521</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.4750</td>\n","      <td>0.000000</td>\n","      <td>0.139136</td>\n","      <td>1.000000</td>\n","      <td>0.683873</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.3250</td>\n","      <td>0.000000</td>\n","      <td>0.015469</td>\n","      <td>0.000000</td>\n","      <td>0.331789</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.4375</td>\n","      <td>0.000000</td>\n","      <td>0.103644</td>\n","      <td>1.000000</td>\n","      <td>0.636672</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.4375</td>\n","      <td>0.000000</td>\n","      <td>0.015713</td>\n","      <td>0.333333</td>\n","      <td>0.334298</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.3375</td>\n","      <td>0.000000</td>\n","      <td>0.025374</td>\n","      <td>0.000000</td>\n","      <td>0.411118</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.2375</td>\n","      <td>0.000000</td>\n","      <td>0.058556</td>\n","      <td>0.333333</td>\n","      <td>0.545154</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.5250</td>\n","      <td>0.333333</td>\n","      <td>0.045771</td>\n","      <td>0.666667</td>\n","      <td>0.505672</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.3250</td>\n","      <td>0.000000</td>\n","      <td>0.058556</td>\n","      <td>0.000000</td>\n","      <td>0.545154</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.4000</td>\n","      <td>0.000000</td>\n","      <td>0.015127</td>\n","      <td>0.000000</td>\n","      <td>0.328210</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 9 columns</p>\n","</div>"],"text/plain":["     Survived  Pclass  Sex     Age     Parch      Fare  Name_length  Fare_log  \\\n","0         0.0     1.0  0.0  0.2750  0.000000  0.014151     0.000000  0.317521   \n","1         1.0     0.0  1.0  0.4750  0.000000  0.139136     1.000000  0.683873   \n","2         1.0     1.0  1.0  0.3250  0.000000  0.015469     0.000000  0.331789   \n","3         1.0     0.0  1.0  0.4375  0.000000  0.103644     1.000000  0.636672   \n","4         0.0     1.0  0.0  0.4375  0.000000  0.015713     0.333333  0.334298   \n","..        ...     ...  ...     ...       ...       ...          ...       ...   \n","886       0.0     0.5  0.0  0.3375  0.000000  0.025374     0.000000  0.411118   \n","887       1.0     0.0  1.0  0.2375  0.000000  0.058556     0.333333  0.545154   \n","888       0.0     1.0  1.0  0.5250  0.333333  0.045771     0.666667  0.505672   \n","889       1.0     0.0  0.0  0.3250  0.000000  0.058556     0.000000  0.545154   \n","890       0.0     1.0  0.0  0.4000  0.000000  0.015127     0.000000  0.328210   \n","\n","     Fare_bin  \n","0         0.0  \n","1         1.0  \n","2         0.0  \n","3         1.0  \n","4         0.0  \n","..        ...  \n","886       0.0  \n","887       1.0  \n","888       1.0  \n","889       1.0  \n","890       0.0  \n","\n","[891 rows x 9 columns]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["# STUDENT CODE HERE\n","\n","std_scaler = StandardScaler()\n","minMax_scaler = MinMaxScaler()\n","data_Standard = pd.DataFrame(std_scaler.fit_transform(data_original), columns=data_original.columns)\n","data_MinMax = pd.DataFrame(minMax_scaler.fit_transform(data_original), columns=data_original.columns)\n","data_Standard\n","data_MinMax\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["#### Evaluieren Sie die Leistung der skalierten Datensätze\n","\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 3.2.19:</b> Trainieren Sie nun ein weiteres Entscheidungsbaummodell mit jedem der neu skalierten Datensätze (DecisionTreeClassifier, random_state = 17)\n","<ul>\n","<li> Berechnen Sie die Korrektklassifikationsrate des Testdatensatzes für beide Datensätze\n","<li> Verwenden Sie eine maximale Tiefe von 3 für den Trainingsprozess\n","\n","</ul>\n","</div>\n","\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["0.7932960893854749"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# Standard Scaler dataset\n","# STUDENT CODE HERE\n","model = DecisionTreeClassifier(random_state=17, max_depth=3)\n","X = data_Standard.drop(columns=[\"Survived\"])\n","Y = data_original['Survived']\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=17)\n","\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","acc3 = accuracy_score(y_test, y_pred)\n","acc3\n","\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/plain":["0.7932960893854749"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["# MinMax Scaler dataset\n","# STUDENT CODE HERE\n","# Standard Scaler dataset\n","# STUDENT CODE HERE\n","model = DecisionTreeClassifier(random_state=17, max_depth=3)\n","X = data_MinMax.drop(columns=[\"Survived\"])\n","Y = data_original['Survived']\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=17)\n","\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","acc4 = accuracy_score(y_test, y_pred)\n","acc4\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 3.2.20:</b> Vergleichen Sie die Korrektklassifikationsrate (engl. accuracy) der Ergebnisse beider Skalierungsoptionen mit der ursprünglichen (ohne skalierte Datensätze) Leistung bei einer Baumtiefe von drei. Was stellen Sie fest? Warum entspricht dieses Ergebnis nicht den Erwartungen? (Vergleichen Sie es nicht mit dem Ergebnis der Kreuzvalidierung) Empfehlen Sie, die Skalierung generell anzuwenden?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"]},{"cell_type":"markdown","metadata":{},"source":["### RandomForests mit scikit-learn\n","\n","Wir verwenden nicht nur einen Entscheidungsbaum, sondern mehrere. Dadurch berücksichtigen wir Ausgaben mehrere Klassifikatoren als nur eine einzige (Ensemble-Methode - in diesem Fall Bagging). RandomForest-Klassifikatoren sind weniger anfällig für Overfit."]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.81 (+/- 0.06)\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","\n","random_forest = RandomForestClassifier(random_state=17)\n","fold = StratifiedKFold(n_splits=5, random_state=17, shuffle=True)\n","\n","scores = cross_val_score(random_forest, X_train, y_train, cv=fold)\n","print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"]},{"cell_type":"markdown","metadata":{},"source":["Fast so gut wie unser optimierter Entscheidungsbaum und besser als unsere nicht optimierte Version, da nur die Standardwerte von RandomForestClassifiers verwendet und nicht optimiert werden. Sie sollten dieses Werkzeug des maschinellen Lernens im Hinterkopf behalten."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"adcb3bd16d314af367f1614e0ea56bd2034d1629567b127c71817280afad7c21"},"kernelspec":{"display_name":"Python 3.7.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}
